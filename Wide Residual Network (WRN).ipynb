{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================== Libaray ========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================= Create conv, batch and relu ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(i_c, o_c, stride=1):\n",
    "    return nn.Conv2d(i_c, o_c, 3, stride, 1, bias=False)\n",
    "\n",
    "class BatchNorm2d(nn.BatchNorm2d):\n",
    "    def __init__(self, channels, momentum=1e-3, eps=1e-3):\n",
    "        super().__init__(channels)\n",
    "        self.update_batch_stats = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.update_batch_stats:\n",
    "            return super().forward(x)\n",
    "        else:\n",
    "            return nn.functional.batch_norm(\n",
    "                x, None, None, self.weight, self.bias, True, self.momentum, self.eps\n",
    "            )\n",
    "\n",
    "def relu():\n",
    "    return nn.LeakyReLU(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================== Create One Residual block ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class residual(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, stride=1, activate_before_residual=False):\n",
    "        super().__init__()\n",
    "        layer = []\n",
    "        if activate_before_residual:\n",
    "            self.pre_act = nn.Sequential(\n",
    "                BatchNorm2d(input_channels),\n",
    "                relu()\n",
    "            )\n",
    "        else:\n",
    "            self.pre_act = nn.Identity()\n",
    "            layer.append(BatchNorm2d(input_channels))\n",
    "            layer.append(relu())\n",
    "        layer.append(conv3x3(input_channels, output_channels, stride))\n",
    "        layer.append(BatchNorm2d(output_channels))\n",
    "        layer.append(relu())\n",
    "        layer.append(conv3x3(output_channels, output_channels))\n",
    "\n",
    "        if stride >= 2 or input_channels != output_channels:\n",
    "            self.identity = nn.Conv2d(input_channels, output_channels, 1, stride, bias=False)\n",
    "        else:\n",
    "            self.identity = nn.Identity()\n",
    "\n",
    "        self.layer = nn.Sequential(*layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pre_act(x)\n",
    "        return self.identity(x) + self.layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============ Create Wide Residual Network (WRN) =============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WRN(nn.Module):\n",
    "    \"\"\" WRN28-width with leaky relu (negative slope is 0.1)\"\"\"\n",
    "    def __init__(self, width, num_classes, transform_fn=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.init_conv = conv3x3(3, 16)\n",
    "\n",
    "        filters = [16, 16*width, 32*width, 64*width]\n",
    "\n",
    "        unit1 = [residual(filters[0], filters[1], activate_before_residual=True)] + \\\n",
    "            [residual(filters[1], filters[1]) for _ in range(1, 4)]\n",
    "        self.unit1 = nn.Sequential(*unit1)\n",
    "\n",
    "        unit2 = [residual(filters[1], filters[2], 2)] + \\\n",
    "            [residual(filters[2], filters[2]) for _ in range(1, 4)]\n",
    "        self.unit2 = nn.Sequential(*unit2)\n",
    "\n",
    "        unit3 = [residual(filters[2], filters[3], 2)] + \\\n",
    "            [residual(filters[3], filters[3]) for _ in range(1, 4)]\n",
    "        self.unit3 = nn.Sequential(*unit3)\n",
    "\n",
    "        self.unit4 = nn.Sequential(*[BatchNorm2d(filters[3]), relu(), nn.AdaptiveAvgPool2d(1)])\n",
    "\n",
    "        self.output = nn.Linear(filters[3], num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")    \n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        self.transform_fn = transform_fn\n",
    "\n",
    "    def forward(self, x, return_feature=False):\n",
    "        if self.training and self.transform_fn is not None:\n",
    "            x = self.transform_fn(x)\n",
    "        x = self.init_conv(x)\n",
    "        x = self.unit1(x)\n",
    "        x = self.unit2(x)\n",
    "        x = self.unit3(x)\n",
    "        f = self.unit4(x)\n",
    "        c = self.output(f.squeeze())\n",
    "        if return_feature:\n",
    "            return [c, f]\n",
    "        else:\n",
    "            return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =========================== Main code==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = WRN(2,10).to(device)\n",
    "model = model.float()\n",
    "summary(model, (3, 64, 64))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
